# Avito Parser — парсер товаров с AI-нормализацией

Программа для автоматического сбора товаров из каталога Avito, нормализации названий через AI и экспорта результатов сравнения цен в Excel.

---

## Что делает программа

Программа работает в три этапа:

**Этап 1 — Парсинг.** Открывает браузер, переходит по ссылке на категорию Avito (с уже настроенными фильтрами), обходит все страницы пагинации и собирает данные каждого товара: название, цену, описание, ссылку, информацию о продавце. Все данные сохраняются в локальную базу SQLite.

**Этап 2 — AI-нормализация.** Отправляет собранные названия товаров в AI-модель (через OpenRouter API). AI анализирует каждое название и определяет унифицированное имя товара. Например, объявления «Игровой ноутбук MSI Thin A15 RTX 4060» и «MSI Thin A15 rtx4060 срочно» будут распознаны как один и тот же товар — «MSI Thin A15 RTX 4060». AI также определяет категорию и ключевые характеристики.

**Этап 3 — Экспорт.** Формирует Excel-файл с одним листом, где все товары собраны в таблицу с автофильтрами. Вы можете отфильтровать товары по нормализованному названию и сравнить цены на одинаковые модели от разных продавцов.

---

## Требования

- **Python** 3.11 или выше
- **Операционная система:** Windows, macOS или Linux
- **API-ключ OpenRouter** для доступа к AI-модели (получить на [openrouter.ai](https://openrouter.ai/))
- **Стабильное интернет-соединение** для парсинга Avito и запросов к AI

---

## Установка

### 1. Клонируйте или скачайте проект

Поместите папку `avito_parser` в удобное место на вашем компьютере.

### 2. Откройте терминал в папке проекта

```bash
cd путь/к/avito_parser
```

### 3. Создайте виртуальное окружение (рекомендуется)

```bash
python -m venv venv
```

Активируйте его:

**Windows:**
```bash
venv\Scripts\activate
```

**macOS / Linux:**
```bash
source venv/bin/activate
```

### 4. Установите зависимости

Основные зависимости:
```bash
pip install -e .
```

Для разработки (линтер, типы, тесты):
```bash
pip install -e ".[dev]"
```

### 5. Установите браузер для Playwright

```bash
playwright install chromium
```

Эта команда скачает Chromium (~150 МБ). Загрузка выполняется один раз.

---

## Настройка

### 1. Создайте файл `.env`

Скопируйте шаблон:

**Windows:**
```bash
copy .env.example .env
```

**macOS / Linux:**
```bash
cp .env.example .env
```

### 2. Заполните обязательные переменные

Откройте файл `.env` в любом текстовом редакторе и заполните:

```env
# Ваш API-ключ OpenRouter (получить на https://openrouter.ai/)
AI_API_KEY=sk-or-v1-ваш-ключ-здесь

# Ссылка на категорию Avito с нужными фильтрами
AVITO_CATEGORY_URL=https://www.avito.ru/moskva/noutbuki
```

### 3. Настройте необязательные параметры (при необходимости)

```env
# Запуск браузера без графического интерфейса (true/false)
# false — вы увидите окно браузера, true — браузер работает в фоне
HEADLESS_MODE=false

# Максимальное количество страниц для парсинга (0 = все страницы)
MAX_PAGES=5

# Уровень логирования (DEBUG — максимум деталей, INFO — стандартный)
LOG_LEVEL=INFO

# Размер батча — сколько товаров отправлять в AI за один запрос
AI_BATCH_SIZE=10

# Путь к файлу Excel с результатами
EXPORT_PATH=data/avito_report.xlsx
```

### Описание всех переменных окружения

| Переменная | Обязательная | По умолчанию | Описание |
|---|---|---|---|
| `AI_API_KEY` | Да | — | API-ключ OpenRouter |
| `AVITO_CATEGORY_URL` | Да | — | URL категории Avito с фильтрами |
| `AI_API_URL` | Нет | `https://openrouter.ai/api/v1/chat/completions` | URL эндпоинта AI API |
| `AI_MODEL` | Нет | `qwen/qwen3.5-plus-02-15` | Модель AI для нормализации |
| `AI_MAX_RETRIES` | Нет | `3` | Количество повторных попыток при ошибке AI |
| `AI_RETRY_DELAY` | Нет | `2.0` | Задержка между попытками (секунды) |
| `AI_BATCH_SIZE` | Нет | `10` | Количество товаров в одном AI-запросе |
| `HEADLESS_MODE` | Нет | `false` | Режим без графического интерфейса |
| `NAVIGATION_TIMEOUT` | Нет | `90000` | Таймаут навигации (мс) |
| `PAGE_WAIT_TIME` | Нет | `30000` | Ожидание после загрузки страницы (мс) |
| `MAX_PAGES` | Нет | `0` | Лимит страниц пагинации (0 = все) |
| `DB_PATH` | Нет | `data/avito_products.db` | Путь к базе данных SQLite |
| `EXPORT_PATH` | Нет | `data/avito_report.xlsx` | Путь к выходному Excel-файлу |
| `LOG_LEVEL` | Нет | `INFO` | Уровень логирования |
| `LOG_FILE_PATH` | Нет | — | Путь к файлу логов (пусто = только консоль) |

---

## Запуск

### Основная команда

```bash
python -m src
```

### Что происходит при запуске

1. Программа загружает настройки из `.env` и проверяет обязательные переменные.
2. Открывается браузер Chromium со stealth-настройками (обход антибот-защиты).
3. Браузер переходит на указанную категорию Avito.
4. Программа собирает данные всех товаров на каждой странице.
5. При наличии пагинации — автоматически переходит на следующие страницы.
6. Собранные данные сохраняются в SQLite (`data/avito_products.db`).
7. Названия товаров отправляются батчами в AI для нормализации.
8. AI определяет унифицированное название, категорию и характеристики.
9. Результаты экспортируются в Excel (`data/avito_report.xlsx`).

### Альтернативный запуск (если установлена как пакет)

```bash
avito-parser
```

---

## Результат — Excel-файл

После успешного запуска в папке `data/` появится файл `avito_report.xlsx` со следующими столбцами:

| Столбец | Описание |
|---|---|
| Нормализованное название | Унифицированное AI-название для группировки одинаковых товаров |
| Категория | Категория товара (Ноутбук, Игровой ноутбук и т.д.) |
| Характеристики | Ключевые характеристики (процессор, видеокарта, RAM, SSD) |
| Цена (руб.) | Цена товара |
| Оригинальное название | Название из объявления на Avito |
| Продавец | Имя или название продавца |
| Рейтинг продавца | Рейтинг продавца на Avito |
| Отзывы | Количество отзывов о продавце |
| Ссылка | Прямая ссылка на объявление (кликабельная) |
| Описание | Краткое описание из объявления |
| Дата парсинга | Дата и время сбора данных |

### Как работать с файлом

1. Откройте файл в Excel или LibreOffice Calc.
2. Используйте автофильтр в столбце «Нормализованное название» — выберите конкретную модель.
3. Отсортируйте по столбцу «Цена» — увидите все предложения от дешёвых к дорогим.
4. Сравните цены на одинаковые товары от разных продавцов.

---

## Архитектура проекта

```
avito_parser/
├── src/
│   ├── __init__.py                  # Корневой пакет, версия
│   ├── __main__.py                  # Точка входа, сборка зависимостей
│   ├── config/
│   │   ├── __init__.py              # Реэкспорт конфигурации
│   │   ├── settings.py              # Загрузка .env, валидация
│   │   └── logger.py                # JSON-логирование с trace_id
│   ├── models/
│   │   ├── __init__.py              # Реэкспорт моделей
│   │   └── product.py               # RawProduct, NormalizedProduct
│   ├── repositories/
│   │   ├── __init__.py              # Реэкспорт репозиториев
│   │   ├── base.py                  # Абстрактный репозиторий (ABC)
│   │   └── sqlite_repository.py     # SQLite-реализация
│   ├── services/
│   │   ├── __init__.py              # Реэкспорт сервисов
│   │   ├── browser_service.py       # Playwright + stealth
│   │   ├── scraper_service.py       # Парсинг + пагинация
│   │   ├── ai_service.py            # OpenRouter API клиент
│   │   ├── normalizer_service.py    # Координация AI-нормализации
│   │   └── export_service.py        # Экспорт в Excel
│   └── utils/
│       ├── __init__.py              # Реэкспорт утилит
│       └── retry.py                 # Retry-декоратор
├── tests/
│   └── __init__.py
├── data/                            # Создаётся автоматически
│   ├── avito_products.db            # База данных SQLite
│   └── avito_report.xlsx            # Результат — Excel-файл
├── .env.example                     # Шаблон переменных окружения
├── .env                             # Ваши настройки (не коммитится)
├── pyproject.toml                   # Конфигурация проекта
└── README.md                        # Этот файл
```

### Принципы архитектуры

Проект построен на принципах SOLID:

- **Single Responsibility.** Каждый модуль отвечает за одну задачу: `browser_service` — за браузер, `scraper_service` — за парсинг, `ai_service` — за AI API, `export_service` — за Excel.
- **Open/Closed.** Компоненты расширяемы без модификации. Например, для добавления нового формата экспорта (CSV, JSON) достаточно создать новый сервис, не меняя существующие.
- **Liskov Substitution.** Репозиторий определён как абстрактный класс (`BaseProductRepository`). SQLite-реализация может быть заменена на PostgreSQL или in-memory хранилище без изменения сервисов.
- **Interface Segregation.** Каждый интерфейс содержит только необходимые методы. Сервисы не зависят от лишних методов других модулей.
- **Dependency Inversion.** Сервисы зависят от абстракций, а не от конкретных реализаций. Все зависимости инжектируются через конструкторы.

### Используемые паттерны

- **Repository** — абстракция над хранилищем данных (SQLite).
- **Service Layer** — бизнес-логика в сервисах, координация между компонентами.
- **Factory** — фабричные функции в `__main__.py` для создания зависимостей.
- **Strategy** — AI-сервис можно заменить на другую реализацию (другой провайдер, локальная модель).
- **Decorator** — retry-декоратор для повторных попыток при сбоях.

### Используемые технологии

| Технология | Назначение |
|---|---|
| Python 3.11+ | Язык программирования |
| Playwright | Автоматизация браузера для парсинга |
| aiohttp | Асинхронные HTTP-запросы к AI API |
| SQLite | Локальная база данных для хранения товаров |
| openpyxl | Создание Excel-файлов |
| python-dotenv | Загрузка переменных окружения из `.env` |
| OpenRouter API | Доступ к AI-модели для нормализации |
| ruff | Линтинг и форматирование кода |
| mypy | Статическая проверка типов |
| pytest | Тестирование |

---

## Инструменты качества кода

### Линтинг и форматирование (ruff)

```bash
# Проверка кода
ruff check src/

# Автоисправление
ruff check src/ --fix

# Форматирование
ruff format src/
```

### Статическая проверка типов (mypy)

```bash
mypy src/
```

### Запуск тестов

```bash
pytest
```

### Pre-commit hooks

Установка хуков для автоматической проверки перед коммитом:

```bash
pre-commit install
```

---

## Устранение неполадок

### Ошибка «Обязательная переменная окружения не задана»

Убедитесь, что файл `.env` существует и содержит заполненные значения `AI_API_KEY` и `AVITO_CATEGORY_URL`. Сверьтесь с `.env.example`.

### Браузер не запускается

Убедитесь, что Chromium установлен:

```bash
playwright install chromium
```

Если вы на Linux-сервере без графического интерфейса, установите `HEADLESS_MODE=true` в `.env`.

### Avito блокирует доступ

Программа использует stealth-настройки для обхода защиты, но иногда Avito может показать CAPTCHA. В этом случае:

- Убедитесь, что `HEADLESS_MODE=false` (браузер с интерфейсом).
- При появлении CAPTCHA — решите её вручную в открытом окне браузера.
- Увеличьте `PAGE_WAIT_TIME` (например, до `60000`).
- Уменьшите `MAX_PAGES` для снижения нагрузки.

### AI API возвращает ошибки

- Проверьте корректность `AI_API_KEY` — ключ должен начинаться с `sk-or-v1-`.
- Проверьте баланс на [openrouter.ai](https://openrouter.ai/).
- Увеличьте `AI_MAX_RETRIES` и `AI_RETRY_DELAY` в `.env`.
- Попробуйте уменьшить `AI_BATCH_SIZE` (например, до `5`).

### Excel-файл не создаётся

Убедитесь, что этап нормализации прошёл успешно — без нормализованных товаров экспорт пропускается. Проверьте логи на наличие ошибок AI.

### Программа работает медленно

- Уменьшите `PAGE_WAIT_TIME` (например, до `10000`).
- Увеличьте `AI_BATCH_SIZE` (например, до `20`) — меньше запросов к AI.
- Ограничьте количество страниц через `MAX_PAGES`.

---

## Повторный запуск

Программа поддерживает повторный запуск:

- **База данных** сохраняется между запусками. Повторный парсинг обновляет существующие товары (по `avito_id`) и добавляет новые.
- **AI-нормализация** обрабатывает только товары, которые ещё не были нормализованы. Уже обработанные пропускаются.
- **Excel-файл** перезаписывается при каждом запуске и содержит все нормализованные товары из базы.

Это значит, что вы можете парсить разные категории (меняя `AVITO_CATEGORY_URL` в `.env`) и накапливать данные в одной базе.

---

## Лицензия

MIT License
